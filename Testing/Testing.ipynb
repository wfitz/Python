{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "\n",
    "- Overview of testing tools focused at the unit level \n",
    "- Some depth, but most of these topics could be their own talk\n",
    "- Disclaimer this talk is for exposure, not for setting team standards\n",
    "\n",
    "### Tools:\n",
    "- Pycodestyle\n",
    "- Pyflakes\n",
    "- Pylint\n",
    "- Doctest\n",
    "- Mypy\n",
    "- Unittest\n",
    "- Pytest \n",
    "- Hypothesis\n",
    "- Stubs and Mocks\n",
    "- Coverage\n",
    "- Tox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why should you use tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When test are well written they allow for the following:\n",
    "- More confidence in committed code\n",
    "- Easier refactoring of code as you can test things quickly after making changes\n",
    "- Extra information on how code is expected to run\n",
    "- Foundation for other good things like good CI/CD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawbacks:\n",
    "- Testing is not a panacea for code bugs\n",
    "- Badly written tests can be as detrimental as good test are helpful\n",
    "- Even having too many \"good\" tests can confuse team members and slow development\n",
    "- Like most things, testing a balancing act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linters\n",
    "- A few common tools you likely have already use... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pycodestyle\n",
    "- https://pycodestyle.pycqa.org/en/latest/\n",
    "- The static analysis tool formally known as pep8\n",
    "- Tells you how non pep8 your code is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyflakes\n",
    "- https://pypi.org/project/pyflakes/\n",
    "- Not focused on pep8 or style, just potential bugs\n",
    "- More conservative than other tools like pylint for calling out items \n",
    "- Lighter weight than some other tools like because only compares a single file at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pylint\n",
    "- http://pylint.pycqa.org/en/latest/\n",
    "- Checks style and code content \n",
    "- Can be a jerk.. \"Your code on a scale from 0 to 10 is -12.7, please try again\" -pylint\n",
    "- Can have a fair amount of false positives and other noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other static checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doctest\n",
    "- https://docs.python.org/3.8/library/doctest.html\n",
    "- Part of the standard library\n",
    "- Python 2 and 3 compatible \n",
    "- Not really for rigorous testing, more of an example with added benefit of some test checks\n",
    "- \"Executable documentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.examples.coding as demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(demo.division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.division??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run from cli with doctest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m doctest -v src/examples/coding.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Or by adding this in your module... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    import doctest \n",
    "    doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mypy\n",
    "- https://mypy.readthedocs.io/en/stable/\n",
    "- Typing info... https://docs.python.org/3/library/typing.html\n",
    "- static type hinting, still lets you use wrong type in run time\n",
    "- Several variants out there from various companies \n",
    "- Old and new way to use based on python versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How some people feel about mypy in python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='mypy.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Older method using comments\n",
    "- Python 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing import List\n",
    "def division(num, denom): # type: (int, int) -> float\n",
    "    temp = [\"temp variable\"] # type: List[str]\n",
    "    return num / denom "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Newer method 3.5(?)+ doesn't need to use comments\n",
    "- 3.6(?) allows for single variable type checks\n",
    "- 3.9 will apparently remove need for typing...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some common usable types..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optional[int]=None\n",
    "Seqeuence[int]\n",
    "Sequence[optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unittest Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Suggestions\n",
    "- Results should be repeatable\n",
    "- Tests should target one thing !!\n",
    "- Tests should be independent !! \n",
    "- Try and test boundary conditions, potential errors, normal working, and None type considerations\n",
    "- Tests should run fast (If they're slow you won't run them as often...)\n",
    "- Use overly descriptive names as much possible for better error analysis on test errors\n",
    "- Writing a broken test before walking away from code can remind you were you left off\n",
    "- Tests are also code... don't forget to treat them as such"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A very quick mention about test driven design (TDD)...\n",
    "\n",
    "Idea:\n",
    "- Add a test\n",
    "- Run test and verify new test that doesn't pass\n",
    "- Write code to make new test pass\n",
    "- Refactor\n",
    "- Confirm test still passes\n",
    "- Repeat until code is complete \n",
    "\n",
    "\n",
    "Benefits:\n",
    "- Requires coder to think about making code more modularized, flexible, and independent\n",
    "- Ideally this acts as a forcing function to think in focused testable units... not huge blobs of code, but building blocks that are easily tested separately and later combined together to achieve the desired coding objective \n",
    "\n",
    "#### \"Code Smells\"\n",
    "- If you have a hard time testing a single function you might need to split it up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest\n",
    "- https://docs.python.org/3.8/library/unittest.html\n",
    "- Python builtin testing library"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this notebook... \n",
    "tox.ini\n",
    "src\n",
    "├── __init__.py\n",
    "├── conftest.py # probably wouldn't put here normally, just an example... \n",
    "├── example\n",
    "│   ├── __init__.py\n",
    "│   ├── stub_sample.py\n",
    "│   └── coding.py\n",
    "└── testing\n",
    "    ├── __init__.py\n",
    "    ├── test_general_pytest.py\n",
    "    ├── test_stub_with_pytest.py\n",
    "    ├── test_coding_with_pytest.py\n",
    "    ├── test_coding_with_unittest.py\n",
    "    └── test_unittest_scope_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lots of asserts to remember..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "self.assertEqual(a, b)\n",
    "self.assertNotEqual(a, b)\n",
    "self.assertTrue(x)\n",
    "self.assertFalse(x)\n",
    "self.assertIs(a, b)\n",
    "self.assertIsNot(a, b)\n",
    "self.assertIsNone(x)\n",
    "self.assertIsNotNone(x)\n",
    "self.assertIn(a, b)\n",
    "self.assertNotIn(a, b)\n",
    "self.assertIsInstance(a, b)\n",
    "self.assertNotIsInstance(a, b)\n",
    "self.assertRaises(exc, fun, *args, **kwds)\n",
    "self.assertRaisesRegex(exc, r, fun, *args, **kwds)\n",
    "self.assertWarns(warn, fun, *args, **kwds)\n",
    "self.assertWarnsRegex(warn, r, fun, *args, **kwds)\n",
    "self.assertLogs(logger, level)\n",
    "self.assertMultiLineEqual(a, b)\n",
    "self.assertSequenceEqual(a, b)\n",
    "self.assertListEqual(a, b)\n",
    "self.assertTupleEqual(a, b)\n",
    "self.assertSetEqual(a, b)\n",
    "self.assertDictEqual(a, b)\n",
    "self.assertAlmostEqual(a, b)\n",
    "self.assertNotAlmostEqual(a, b)\n",
    "self.assertGreater(a, b)\n",
    "self.assertGreaterEqual(a, b)\n",
    "self.assertLess(a, b)\n",
    "self.assertLessEqual(a, b)\n",
    "self.assertRegex(s, r)\n",
    "self.assertNotRegex(s, r)\n",
    "self.assertCountEqual(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can call tests in a multitude of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m unittest -h\n",
    "python -m unittest test_module1 test_module2\n",
    "python -m unittest test_module.TestClass\n",
    "python -m unittest test_module.TestClass.test_method\n",
    "python -m unittest -v test_module\n",
    "python -m unittest discover <test_directory>\n",
    "python -m unittest discover -s <directory> -p '*_test.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Various ways to skip tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unittest.skip(\"demonstrating skipping\")\n",
    "@unittest.skipIf(sys.version_info[0] > 2, \"Python 2 only test\")\n",
    "@unittest.skipUnless(sys.platform.startswith(\"win\"), \"Only for Windows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If setUp() succeeded, the tearDown() method will be run whether runTest() succeeded or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest\n",
    "- https://docs.pytest.org/en/stable/contents.html\n",
    "- pytest --help\n",
    "- From unittest docs... \"pytest: Third-party unittest framework with a lighter-weight syntax for writing tests. For example, assert func(10) == 42\"\n",
    "- Tests can be functions or classes similar to unittest\n",
    "- Supports unittest and other runners\n",
    "- Much more options, plugins, etc compared to unittest\n",
    "- Seems to be industry standard\n",
    "- Assert has special powers in pytest, no need to remember all the unittest asserts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pytest --setup-show test_add.py -k valid_id\n",
    "python -m pytest -v\n",
    "python -m pytest -v --doctest-modules\n",
    "python -m pytest src/testing/module.py::funcOrClass\n",
    "lots of others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametrize testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('nom, denom, result', \n",
    "                         [(2, 4, .5), \n",
    "                          (1, 3, pytest.approx(.333, .1))])\n",
    "def test_division_with_parametrize(nom, denom, result):\n",
    "    \"\"\"Same as division with two ints, but with parametrize\"\"\"\n",
    "    assert division(nom, denom) == result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixtures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fixtures are similar to setup and teardown in unittest \n",
    "- Some args like autouse means these fixtures will be auto invoked at their respective scopes\n",
    "- Args can also include fixture scope: function, class, module, or session\n",
    "\n",
    "- conftest.py is module pytest knows to look for scope specific fixtures.. all sub folders have access to conftest, can have multiple. Doesn't need to be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pytest --fixtures\n",
    "# builtin fixtures available for usage... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ^ builtin fixtures available for usage... \n",
    "- Items such as tmpdir fixtures allow you to create temporary directories to create files or directories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can mark tests using a decorator... will complain though if you don't add to ini file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.this\n",
    "@pytest.mark.that\n",
    "pytest -m \"this and that\"\n",
    "pytest -m \"this or that\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can skip tests like unittest as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.skip(reason='misunderstood the API')\n",
    "@pytest.mark.skipif(sys.version_info[0] > 2, reason=\"Python 2 only test\")\n",
    "@pytest.mark.xfail(sys.version_info[0] > 2, reason=\"Python 2 only test\") # mark expected to fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis \n",
    "- https://hypothesis.readthedocs.io/en/latest/details.html\n",
    "- Show stats with --hypothesis-show-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@given(st.integers(), st.integers())\n",
    "def test_with_hypothesis_ints(num, denom):\n",
    "    \"\"\"Stress test for potential errors\"\"\"\n",
    "    #assume(denom > 0)\n",
    "    division(num, denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stubs and Mocks\n",
    "- https://docs.python.org/3/library/unittest.mock.html (since 3.3)\n",
    "- Stubs for overwriting a namespace and providing a return value\n",
    "- Mocks for overwriting a namespace and checking behavior (did it get called, etc...)\n",
    "- Really good: https://www.youtube.com/watch?v=ww1UsGZV8fQ\n",
    "- pytest also has monkey patching... we'll look at unittest mock today though\n",
    "\n",
    "#####  When to consider a stub or mock: \n",
    "- To bypass complicated code \n",
    "- Remove outside dependencies from a test\n",
    "- Avoid using something that is overly slow (Tests should be fast)\n",
    "- Represent external resources (Avoid networks, databases, etc)\n",
    "- Supply non-predictable values\n",
    "- The code in question doesn't exist... test while waiting for others to write their code\n",
    "\n",
    "###### \"Code Smells\"\n",
    "- Red flags should be raised when everything is patched... potentially means a lot of dependencies the way code is written\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage\n",
    "- How much of your code did you touch with testing?\n",
    "- Doesn't necessary mean it was good testing, just that it was exercised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage run -m pytest src/examples/coding.py src/testing/test_coding_with_pytest.py \n",
    "coverage run -m pytest\n",
    "coverage report\n",
    "coverage html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's add some short circuit code in the original coding.py..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and this_wont_raise_an_error(): \n",
    "      but_linting_will_find_it() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tox\n",
    "- https://tox.readthedocs.io/en/latest/\n",
    "- Test code in multiple versions of python using a virtual env\n",
    "- Good for more than just py2 to py3 checks, but also different py3 versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cat tox.ini \n",
    "[tox]\n",
    "envlist = py38,py27\n",
    "skipsdist = True # get around no setup.py\n",
    "\n",
    "[testenv]\n",
    "deps = pytest\n",
    "commands = python -m pytest src/testing/ -v --doctest-modules\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
